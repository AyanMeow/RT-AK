{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_image,y_train_label),(x_test_image,y_test_label) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train_normalize = x_train_image.astype('float32')/255\n",
    "x_test_normalize = x_test_image.astype('float32')/255\n",
    "y_train_OneHot = tf.keras.utils.to_categorical(y_train_label)\n",
    "y_test_OneHot = tf.keras.utils.to_categorical(y_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 96)   14112       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 16, 16, 96)   384         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus (TensorFlo [(None, 16, 16, 96)] 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh (TensorFlowOpL [(None, 16, 16, 96)] 0           tf_op_layer_Softplus[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [(None, 16, 16, 96)] 0           batch_normalization[0][0]        \n",
      "                                                                 tf_op_layer_Tanh[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 96)     0           tf_op_layer_Mul[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 16)     1536        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8, 8, 16)     64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_1 (TensorF [(None, 8, 8, 16)]   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_1 (TensorFlowO [(None, 8, 8, 16)]   0           tf_op_layer_Softplus_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_1 (TensorFlowOp [(None, 8, 8, 16)]   0           batch_normalization_1[0][0]      \n",
      "                                                                 tf_op_layer_Tanh_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 64)     1024        tf_op_layer_Mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 64)     9216        tf_op_layer_Mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 8, 8, 64)     256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 64)     256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_2 (TensorF [(None, 8, 8, 64)]   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_3 (TensorF [(None, 8, 8, 64)]   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_2 (TensorFlowO [(None, 8, 8, 64)]   0           tf_op_layer_Softplus_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_3 (TensorFlowO [(None, 8, 8, 64)]   0           tf_op_layer_Softplus_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_2 (TensorFlowOp [(None, 8, 8, 64)]   0           batch_normalization_2[0][0]      \n",
      "                                                                 tf_op_layer_Tanh_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_3 (TensorFlowOp [(None, 8, 8, 64)]   0           batch_normalization_3[0][0]      \n",
      "                                                                 tf_op_layer_Tanh_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 128)    0           tf_op_layer_Mul_2[0][0]          \n",
      "                                                                 tf_op_layer_Mul_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 16)     2048        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 8, 8, 16)     64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_4 (TensorF [(None, 8, 8, 16)]   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_4 (TensorFlowO [(None, 8, 8, 16)]   0           tf_op_layer_Softplus_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_4 (TensorFlowOp [(None, 8, 8, 16)]   0           batch_normalization_4[0][0]      \n",
      "                                                                 tf_op_layer_Tanh_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 64)     1024        tf_op_layer_Mul_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 8, 64)     9216        tf_op_layer_Mul_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 8, 8, 64)     256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 64)     256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_5 (TensorF [(None, 8, 8, 64)]   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_6 (TensorF [(None, 8, 8, 64)]   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_5 (TensorFlowO [(None, 8, 8, 64)]   0           tf_op_layer_Softplus_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_6 (TensorFlowO [(None, 8, 8, 64)]   0           tf_op_layer_Softplus_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_5 (TensorFlowOp [(None, 8, 8, 64)]   0           batch_normalization_5[0][0]      \n",
      "                                                                 tf_op_layer_Tanh_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_6 (TensorFlowOp [(None, 8, 8, 64)]   0           batch_normalization_6[0][0]      \n",
      "                                                                 tf_op_layer_Tanh_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 128)    0           tf_op_layer_Mul_5[0][0]          \n",
      "                                                                 tf_op_layer_Mul_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 32)     4096        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 8, 32)     128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_7 (TensorF [(None, 8, 8, 32)]   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_7 (TensorFlowO [(None, 8, 8, 32)]   0           tf_op_layer_Softplus_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_7 (TensorFlowOp [(None, 8, 8, 32)]   0           batch_normalization_7[0][0]      \n",
      "                                                                 tf_op_layer_Tanh_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 128)    4096        tf_op_layer_Mul_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 128)    36864       tf_op_layer_Mul_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 128)    512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 128)    512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_8 (TensorF [(None, 8, 8, 128)]  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_9 (TensorF [(None, 8, 8, 128)]  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_8 (TensorFlowO [(None, 8, 8, 128)]  0           tf_op_layer_Softplus_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_9 (TensorFlowO [(None, 8, 8, 128)]  0           tf_op_layer_Softplus_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_8 (TensorFlowOp [(None, 8, 8, 128)]  0           batch_normalization_8[0][0]      \n",
      "                                                                 tf_op_layer_Tanh_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_9 (TensorFlowOp [(None, 8, 8, 128)]  0           batch_normalization_9[0][0]      \n",
      "                                                                 tf_op_layer_Tanh_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 256)    0           tf_op_layer_Mul_8[0][0]          \n",
      "                                                                 tf_op_layer_Mul_9[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 256)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 4, 4, 32)     8192        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 4, 4, 32)     128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_10 (Tensor [(None, 4, 4, 32)]   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_10 (TensorFlow [(None, 4, 4, 32)]   0           tf_op_layer_Softplus_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_10 (TensorFlowO [(None, 4, 4, 32)]   0           batch_normalization_10[0][0]     \n",
      "                                                                 tf_op_layer_Tanh_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 4, 4, 128)    4096        tf_op_layer_Mul_10[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 128)    36864       tf_op_layer_Mul_10[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 4, 4, 128)    512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 4, 128)    512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_11 (Tensor [(None, 4, 4, 128)]  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_12 (Tensor [(None, 4, 4, 128)]  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_11 (TensorFlow [(None, 4, 4, 128)]  0           tf_op_layer_Softplus_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_12 (TensorFlow [(None, 4, 4, 128)]  0           tf_op_layer_Softplus_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_11 (TensorFlowO [(None, 4, 4, 128)]  0           batch_normalization_11[0][0]     \n",
      "                                                                 tf_op_layer_Tanh_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_12 (TensorFlowO [(None, 4, 4, 128)]  0           batch_normalization_12[0][0]     \n",
      "                                                                 tf_op_layer_Tanh_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 4, 4, 256)    0           tf_op_layer_Mul_11[0][0]         \n",
      "                                                                 tf_op_layer_Mul_12[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 4, 48)     12288       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 4, 4, 48)     192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_13 (Tensor [(None, 4, 4, 48)]   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_13 (TensorFlow [(None, 4, 4, 48)]   0           tf_op_layer_Softplus_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_13 (TensorFlowO [(None, 4, 4, 48)]   0           batch_normalization_13[0][0]     \n",
      "                                                                 tf_op_layer_Tanh_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 4, 4, 192)    9216        tf_op_layer_Mul_13[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 4, 4, 192)    82944       tf_op_layer_Mul_13[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 4, 4, 192)    768         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 4, 192)    768         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_14 (Tensor [(None, 4, 4, 192)]  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_15 (Tensor [(None, 4, 4, 192)]  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_14 (TensorFlow [(None, 4, 4, 192)]  0           tf_op_layer_Softplus_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_15 (TensorFlow [(None, 4, 4, 192)]  0           tf_op_layer_Softplus_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_14 (TensorFlowO [(None, 4, 4, 192)]  0           batch_normalization_14[0][0]     \n",
      "                                                                 tf_op_layer_Tanh_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_15 (TensorFlowO [(None, 4, 4, 192)]  0           batch_normalization_15[0][0]     \n",
      "                                                                 tf_op_layer_Tanh_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 4, 4, 384)    0           tf_op_layer_Mul_14[0][0]         \n",
      "                                                                 tf_op_layer_Mul_15[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 4, 4, 48)     18432       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 4, 4, 48)     192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_16 (Tensor [(None, 4, 4, 48)]   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_16 (TensorFlow [(None, 4, 4, 48)]   0           tf_op_layer_Softplus_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_16 (TensorFlowO [(None, 4, 4, 48)]   0           batch_normalization_16[0][0]     \n",
      "                                                                 tf_op_layer_Tanh_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 4, 4, 192)    9216        tf_op_layer_Mul_16[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 4, 4, 192)    82944       tf_op_layer_Mul_16[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 4, 192)    768         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 4, 4, 192)    768         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_17 (Tensor [(None, 4, 4, 192)]  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_18 (Tensor [(None, 4, 4, 192)]  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_17 (TensorFlow [(None, 4, 4, 192)]  0           tf_op_layer_Softplus_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_18 (TensorFlow [(None, 4, 4, 192)]  0           tf_op_layer_Softplus_18[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_17 (TensorFlowO [(None, 4, 4, 192)]  0           batch_normalization_17[0][0]     \n",
      "                                                                 tf_op_layer_Tanh_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_18 (TensorFlowO [(None, 4, 4, 192)]  0           batch_normalization_18[0][0]     \n",
      "                                                                 tf_op_layer_Tanh_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 4, 4, 384)    0           tf_op_layer_Mul_17[0][0]         \n",
      "                                                                 tf_op_layer_Mul_18[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 4, 4, 64)     24576       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 4, 4, 64)     256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_19 (Tensor [(None, 4, 4, 64)]   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_19 (TensorFlow [(None, 4, 4, 64)]   0           tf_op_layer_Softplus_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_19 (TensorFlowO [(None, 4, 4, 64)]   0           batch_normalization_19[0][0]     \n",
      "                                                                 tf_op_layer_Tanh_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 4, 4, 256)    16384       tf_op_layer_Mul_19[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 4, 4, 256)    147456      tf_op_layer_Mul_19[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 4, 4, 256)    1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 4, 4, 256)    1024        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_20 (Tensor [(None, 4, 4, 256)]  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_21 (Tensor [(None, 4, 4, 256)]  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_20 (TensorFlow [(None, 4, 4, 256)]  0           tf_op_layer_Softplus_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_21 (TensorFlow [(None, 4, 4, 256)]  0           tf_op_layer_Softplus_21[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_20 (TensorFlowO [(None, 4, 4, 256)]  0           batch_normalization_20[0][0]     \n",
      "                                                                 tf_op_layer_Tanh_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_21 (TensorFlowO [(None, 4, 4, 256)]  0           batch_normalization_21[0][0]     \n",
      "                                                                 tf_op_layer_Tanh_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 4, 4, 512)    0           tf_op_layer_Mul_20[0][0]         \n",
      "                                                                 tf_op_layer_Mul_21[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 512)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 2, 2, 64)     32768       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 2, 2, 64)     256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_22 (Tensor [(None, 2, 2, 64)]   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_22 (TensorFlow [(None, 2, 2, 64)]   0           tf_op_layer_Softplus_22[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_22 (TensorFlowO [(None, 2, 2, 64)]   0           batch_normalization_22[0][0]     \n",
      "                                                                 tf_op_layer_Tanh_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 2, 2, 256)    16384       tf_op_layer_Mul_22[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 2, 2, 256)    147456      tf_op_layer_Mul_22[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 2, 2, 256)    1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 2, 2, 256)    1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_23 (Tensor [(None, 2, 2, 256)]  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus_24 (Tensor [(None, 2, 2, 256)]  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_23 (TensorFlow [(None, 2, 2, 256)]  0           tf_op_layer_Softplus_23[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh_24 (TensorFlow [(None, 2, 2, 256)]  0           tf_op_layer_Softplus_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_23 (TensorFlowO [(None, 2, 2, 256)]  0           batch_normalization_23[0][0]     \n",
      "                                                                 tf_op_layer_Tanh_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_24 (TensorFlowO [(None, 2, 2, 256)]  0           batch_normalization_24[0][0]     \n",
      "                                                                 tf_op_layer_Tanh_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 2, 2, 512)    0           tf_op_layer_Mul_23[0][0]         \n",
      "                                                                 tf_op_layer_Mul_24[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           20490       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 764,842\n",
      "Trainable params: 758,890\n",
      "Non-trainable params: 5,952\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class SqueezeNet(keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SqueezeNet, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(filters=96, kernel_size=7, strides=2, padding='same', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.act1 = Mish()\n",
    "        self.pool1 = layers.MaxPool2D(3, strides=2, padding='same')\n",
    "        self.fire_block2 = FireBlock(16, 64, 64)\n",
    "        self.fire_block3 = FireBlock(16, 64, 64)\n",
    "        self.fire_block4 = FireBlock(32, 128, 128)\n",
    "        self.pool4 = layers.MaxPool2D(3, strides=2, padding='same')\n",
    "        self.fire_block5 = FireBlock(32, 128, 128)\n",
    "        self.fire_block6 = FireBlock(48, 192, 192)\n",
    "        self.fire_block7 = FireBlock(48, 192, 192)\n",
    "        self.fire_block8 = FireBlock(64, 256, 256)\n",
    "        self.pool8 = layers.MaxPool2D(3, strides=2, padding='same')\n",
    "        self.fire_block9 = FireBlock(64, 256, 256)\n",
    "\n",
    "    def __call__(self, inputs=None):\n",
    "        if not inputs:\n",
    "            #inputs = keras.Input(shape=(224, 224, 3))\n",
    "            inputs = keras.Input(shape=(32, 32, 3))\n",
    "\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.pool1(x)  # C2\n",
    "        x = self.fire_block2(x)\n",
    "        x = self.fire_block3(x)\n",
    "        x = self.fire_block4(x)\n",
    "        x = self.pool4(x)  # C3\n",
    "        x = self.fire_block5(x)\n",
    "        x = self.fire_block6(x)\n",
    "        x = self.fire_block7(x)\n",
    "        x = self.fire_block8(x)\n",
    "        x = self.pool8(x)  # C4\n",
    "        x = self.fire_block9(x)\n",
    "\n",
    "        x = keras.layers.Flatten()(x)\n",
    "        x = keras.layers.Dense(10,activation='softmax')(x)\n",
    "\n",
    "        squeezenet = keras.Model(inputs, x)\n",
    "        return squeezenet\n",
    "\n",
    "\n",
    "class FireBlock(layers.Layer):\n",
    "\n",
    "    def __init__(self, filter1, filter2, filter3):\n",
    "        super(FireBlock, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(filters=filter1, kernel_size=1, padding='same', use_bias=False)\n",
    "        self.conv2 = layers.Conv2D(filters=filter2, kernel_size=1, padding='same', use_bias=False)\n",
    "        self.conv3 = layers.Conv2D(filters=filter3, kernel_size=3, padding='same', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        squeeze_x = self.conv1(inputs)\n",
    "        squeeze_x = self.bn1(squeeze_x)\n",
    "        squeeze_x = Mish()(squeeze_x)\n",
    "        expand_x1 = self.conv2(squeeze_x)\n",
    "        expand_x1 = self.bn2(expand_x1)\n",
    "        expand_x1 = Mish()(expand_x1)\n",
    "        expand_x3 = self.conv3(squeeze_x)\n",
    "        expand_x3 = self.bn3(expand_x3)\n",
    "        expand_x3 = Mish()(expand_x3)\n",
    "\n",
    "        merge_x = layers.Concatenate()([expand_x1, expand_x3])\n",
    "\n",
    "        return merge_x\n",
    "\n",
    "\n",
    "class Mish(layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Mish, self).__init__()\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return tf.multiply(inputs, tf.tanh(tf.nn.softplus(inputs)))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    squeeze_net = SqueezeNet()\n",
    "    model = squeeze_net()\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 1.6333 - accuracy: 0.4067 - val_loss: 2.8308 - val_accuracy: 0.0997\n",
      "Epoch 2/10\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.2668 - accuracy: 0.5426 - val_loss: 3.2541 - val_accuracy: 0.1172\n",
      "Epoch 3/10\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0905 - accuracy: 0.6104 - val_loss: 1.7776 - val_accuracy: 0.4016\n",
      "Epoch 4/10\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.9547 - accuracy: 0.6614 - val_loss: 1.5761 - val_accuracy: 0.4983\n",
      "Epoch 5/10\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.8409 - accuracy: 0.7034 - val_loss: 1.2382 - val_accuracy: 0.5828\n",
      "Epoch 6/10\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.7488 - accuracy: 0.7341 - val_loss: 1.1902 - val_accuracy: 0.6102\n",
      "Epoch 7/10\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.6545 - accuracy: 0.7696 - val_loss: 1.3147 - val_accuracy: 0.5986\n",
      "Epoch 8/10\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.5804 - accuracy: 0.7917 - val_loss: 1.2602 - val_accuracy: 0.6342\n",
      "Epoch 9/10\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.5108 - accuracy: 0.8189 - val_loss: 1.2274 - val_accuracy: 0.6457\n",
      "Epoch 10/10\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.4528 - accuracy: 0.8394 - val_loss: 1.4664 - val_accuracy: 0.5971\n"
     ]
    }
   ],
   "source": [
    "#model = keras.models.Model(input,x)\n",
    "squeeze_net = SqueezeNet()\n",
    "model = squeeze_net()\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model_train = model.fit(x=x_train_normalize,y=y_train_OneHot,validation_split=0.2,epochs=10,batch_size=300,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_history(model_train,train,val):\n",
    "    plt.plot(model_train.history[train])\n",
    "    plt.plot(model_train.history[val])\n",
    "    plt.title('Train History')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel(train)\n",
    "    plt.legend(['train','validation'],loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_history(model_train,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 1.4857 - accuracy: 0.5923\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test_normalize,y_test_OneHot,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./SqueezeNet.h5', save_format=\"h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "191b613aa2eae5cea452075f03b52477f36862f57e511f6bd3e69cb00abfb340"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
